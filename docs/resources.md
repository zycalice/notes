---
title: resources
permalink: /resources/
---

# Resources
[<< Back to my website](https://zycalice.github.io/)

## Efficient Algorithm
- Stanford, NP-Completeness: [http://web.stanford.edu/class/archive/cs/cs103/cs103.1152/lectures/27/Small27.pdf](http://web.stanford.edu/class/archive/cs/cs103/cs103.1152/lectures/27/Small27.pdf)

## Discrete Math
- Berkeley: [https://www.eecs70.org/](https://www.eecs70.org/)

## Statistics
- CTT: [https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_probability/BS704_Probability12.html](https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_probability/BS704_Probability12.html)
- CLT: [https://www.me.psu.edu/cimbala/me345/Lectures/Central_Limit_Theorem.pdf](https://www.me.psu.edu/cimbala/me345/Lectures/Central_Limit_Theorem.pdf)
- Regression to mean and how to remove it: [https://www.iwh.on.ca/what-researchers-mean-by/regression-to-mean](https://www.iwh.on.ca/what-researchers-mean-by/regression-to-mean)

## PAC Learning and VC dimention
- CMU: [https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture28-pac.pdf](https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture28-pac.pdf)
- Princeton: [https://www.cs.princeton.edu/courses/archive/spring15/cos511/notes/lec3.pdf](https://www.cs.princeton.edu/courses/archive/spring15/cos511/notes/lec3.pdf)
- Washington: [https://courses.cs.washington.edu/courses/cse546/12wi/slides/cse546wi12LearningTheory.pdf](https://courses.cs.washington.edu/courses/cse546/12wi/slides/cse546wi12LearningTheory.pdf)

## Type of Learning Models
- Washington: [https://sites.stat.washington.edu/mmp/courses/stat535/fall18/Handouts/l2slides-prediction-concepts.pdf](https://sites.stat.washington.edu/mmp/courses/stat535/fall18/Handouts/l2slides-prediction-concepts.pdf)

## Bayes Net
- Bayes Belief Nets: [https://plato.stanford.edu/entries/artificial-intelligence/bayesian-nets.html](https://plato.stanford.edu/entries/artificial-intelligence/bayesian-nets.html)
- Naive Bayes CMU: [http://www.cs.cmu.edu/~10601b/slides/NBayes.pdf](http://www.cs.cmu.edu/~10601b/slides/NBayes.pdf)

## Hidden Markov Model
- CMU: [http://www.cs.cmu.edu/~tbergkir/11711fa17/recitation4_notes.pdf](http://www.cs.cmu.edu/~tbergkir/11711fa17/recitation4_notes.pdf)

## Recurrent Neural Network
- Stanford: [https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)

## Linear Regression and Logistic Regression
- Pearson and Spearman Correlation Comparison: [https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/a-comparison-of-the-pearson-and-spearman-correlation-methods/](https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/a-comparison-of-the-pearson-and-spearman-correlation-methods/)
- Logistic regression: [https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/#:~:text=In%20general%2C%20we%20can%20have,in%20a%20logistic%20regression%20model.&text=Each%20exponentiated%20coefficient%20is%20the,other%20variables%20at%20certain%20value.](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/#:~:text=In%20general%2C%20we%20can%20have,in%20a%20logistic%20regression%20model.&text=Each%20exponentiated%20coefficient%20is%20the,other%20variables%20at%20certain%20value.)


## Trees:
- GTech: [https://mdav.ece.gatech.edu/ece-6254-spring2017/notes/22-decision-trees.pdf](https://mdav.ece.gatech.edu/ece-6254-spring2017/notes/22-decision-trees.pdf)

## Gradient Descent
- UBC: [https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/L4.pdf](https://www.cs.ubc.ca/~schmidtm/Courses/540-W18/L4.pdf)
- Berkeley: [https://people.eecs.berkeley.edu/~jordan/kernels/0521813972c03_p47-84.pdf](https://people.eecs.berkeley.edu/~jordan/kernels/0521813972c03_p47-84.pdf)

## Kernel
- Berkeley: [https://people.eecs.berkeley.edu/~jordan/kernels/0521813972c02_p25-46.pdf](https://people.eecs.berkeley.edu/~jordan/kernels/0521813972c02_p25-46.pdf)

## Online Learning
- MIT: [https://www.mit.edu/~9.520/spring11/slides/class15_online.pdf](https://www.mit.edu/~9.520/spring11/slides/class15_online.pdf)
- [http://www.ciml.info/dl/v0_8/ciml-v0_8-ch03.pdf](http://www.ciml.info/dl/v0_8/ciml-v0_8-ch03.pdf)

## Support Vector Machine
- [https://www.robots.ox.ac.uk/~az/lectures/ml/lect2.pdf](https://www.robots.ox.ac.uk/~az/lectures/ml/lect2.pdf)
- Berkeley: [https://www.eecs189.org/static/notes/n20.pdf](https://www.eecs189.org/static/notes/n20.pdf)
- CMU: [http://www.cs.cmu.edu/~aarti/Class/10701_Spring14/slides/SupportVectorMachines.pdf](http://www.cs.cmu.edu/~aarti/Class/10701_Spring14/slides/SupportVectorMachines.pdf)
- Toronto: [http://www.cs.toronto.edu/~mbrubake/teaching/C11/Handouts/SupportVectorMachines.pdf](http://www.cs.toronto.edu/~mbrubake/teaching/C11/Handouts/SupportVectorMachines.pdf)
- Cornell: [https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote09.html](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote09.html)

## Principal Component Analysis
- Covariance Matrix Definition: [https://www.itl.nist.gov/div898/handbook/pmc/section5/pmc541.htm](https://www.itl.nist.gov/div898/handbook/pmc/section5/pmc541.htm)
- SVD: [http://web.mit.edu/course/other/be.400/OldFiles/www/SVD/Singular_Value_Decomposition.htm](http://web.mit.edu/course/other/be.400/OldFiles/www/SVD/Singular_Value_Decomposition.htm)
- PCA derivation: [https://www.eecs189.org/static/notes/n10.pdf](https://www.eecs189.org/static/notes/n10.pdf)

## Autoencoders
- DeepLearningBook: [https://www.deeplearningbook.org/contents/autoencoders.html](https://www.deeplearningbook.org/contents/autoencoders.html)
- VAE: [https://arxiv.org/pdf/1606.05908.pdf](https://arxiv.org/pdf/1606.05908.pdf)
- Autoencoder using label information: [https://jmlr.csail.mit.edu/papers/volume13/snoek12a/snoek12a.pdf](https://jmlr.csail.mit.edu/papers/volume13/snoek12a/snoek12a.pdf)

## Cross Validation
- Error and validation: [http://www.stat.cmu.edu/~ryantibs/advmethods/notes/errval.pdf](http://www.stat.cmu.edu/~ryantibs/advmethods/notes/errval.pdf)
- K-Fold cross validation: [http://statweb.stanford.edu/~tibs/sta306bfiles/cvwrong.pdf](http://statweb.stanford.edu/~tibs/sta306bfiles/cvwrong.pdf)
- DataCamp practice: [https://campus.datacamp.com/courses/model-validation-in-python/cross-validation?ex=6](https://campus.datacamp.com/courses/model-validation-in-python/cross-validation?ex=6)

## NLP
- N-gram: [https://web.stanford.edu/~jurafsky/slp3/3.pdf](https://web.stanford.edu/~jurafsky/slp3/3.pdf)
- Eigenwords: [https://jmlr.csail.mit.edu/papers/volume16/dhillon15a/dhillon15a.pdf](https://jmlr.csail.mit.edu/papers/volume16/dhillon15a/dhillon15a.pdf)
- NLP and argument: [https://www.aclweb.org/anthology/P16-5002/](https://www.aclweb.org/anthology/P16-5002/)
- NLP and persuasion: [https://nlds.soe.ucsc.edu/persuasion_persona](https://nlds.soe.ucsc.edu/persuasion_persona)
- Seq to Seq and Attention for NLP: [https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)
- Encoder Decoder with Attention: [https://bastings.github.io/annotated_encoder_decoder/](https://bastings.github.io/annotated_encoder_decoder/)
- Latent Dirtchlet Allocation/Topic Modeling: [https://www.cl.cam.ac.uk/teaching/1213/L101/clark_lectures/lect7.pdf](https://www.cl.cam.ac.uk/teaching/1213/L101/clark_lectures/lect7.pdf)

## Deep Learning
- Bandit algorithm: [https://tor-lattimore.com/downloads/book/book.pdf](https://tor-lattimore.com/downloads/book/book.pdf)
- Visual Question Answering: [https://visualqa.org/](https://visualqa.org/)
- Berkeley STAT Course: [https://courses.d2l.ai/berkeley-stat-157/index.html](https://courses.d2l.ai/berkeley-stat-157/index.html)
- Berkeley CS Course: [https://bcourses.berkeley.edu/courses/1487769](https://bcourses.berkeley.edu/courses/1487769); [https://www2.eecs.berkeley.edu/Courses/CS282A/](https://www2.eecs.berkeley.edu/Courses/CS282A/)
- Berkeley CS Course: [https://sites.google.com/view/berkeley-cs294-158-sp20/home](https://sites.google.com/view/berkeley-cs294-158-sp20/home)
- UPenn ESE Course: [https://pratikac.github.io/pub/19_ese546.pdf?fbclid=IwAR1Z-QyDU8VZqY9c0yUha1LoaaPuwqVXfzqTbPd7RpfP-MR-e774Nke3M1k](https://pratikac.github.io/pub/19_ese546.pdf?fbclid=IwAR1Z-QyDU8VZqY9c0yUha1LoaaPuwqVXfzqTbPd7RpfP-MR-e774Nke3M1k)
- UPenn CIS Course: [https://www.seas.upenn.edu/~cis522/schedule.html](https://www.seas.upenn.edu/~cis522/schedule.html)
- Harvard Advanced Data Science Course: [https://harvard-iacs.github.io/2020F-AC295/pages/materials.html](https://harvard-iacs.github.io/2020F-AC295/pages/materials.html)

## Reinforcement Learning
- Sutton Book: [http://incompleteideas.net/book/RLbook2020.pdf](http://incompleteideas.net/book/RLbook2020.pdf)
- CMU: [https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture26-ri.pdf](https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture26-ri.pdf)
- Blog, Nice Overview: [https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html](https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html)

## Evaluation
- Precision and recall: [https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)
- Precision and recall: [https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)
- Precision, recall, sensitivity and specificity: [https://deepai.org/machine-learning-glossary-and-terms/precision-and-recall](https://deepai.org/machine-learning-glossary-and-terms/precision-and-recall)
- Precision, recall, sensitivity and specificity: [http://cs229.stanford.edu/section/evaluation_metrics_spring2020.pdf](http://cs229.stanford.edu/section/evaluation_metrics_spring2020.pdf)
- Harvard: [https://scholar.harvard.edu/files/msseo/files/5.convergence_informatics_week5.pdf](https://scholar.harvard.edu/files/msseo/files/5.convergence_informatics_week5.pdf)

## Model Explanations:
- LIME: [https://homes.cs.washington.edu/~marcotcr/blog/lime/](https://homes.cs.washington.edu/~marcotcr/blog/lime/)
- LIME Paper: [https://arxiv.org/pdf/1602.04938v1.pdf](https://arxiv.org/pdf/1602.04938v1.pdf)
- LIME GitHub: [https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)
- LIME Tutorial: [https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html](https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html)

## Interpretable ML
- [https://christophm.github.io/interpretable-ml-book/limo.html](https://christophm.github.io/interpretable-ml-book/limo.html)

## Tools
- GitPages: [https://docs.github.com/en/free-pro-team@latest/github/working-with-github-pages](https://docs.github.com/en/free-pro-team@latest/github/working-with-github-pages)
- Jekyllrb: [https://jekyllrb.com/docs/github-pages/](https://jekyllrb.com/docs/github-pages/)
- Front Matter: [https://jekyllrb.com/docs/front-matter/](https://jekyllrb.com/docs/front-matter/)
- JSON resume: [https://jsonresume.org/getting-started/](https://jsonresume.org/getting-started/)

## Pytorch
- Pytorch Intro Examples: [https://pytorch.org/tutorials/beginner/pytorch_with_examples.html](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)
- Pytorch Access Weights: [https://discuss.pytorch.org/t/access-weights-of-a-specific-module-in-nn-sequential/3627](https://discuss.pytorch.org/t/access-weights-of-a-specific-module-in-nn-sequential/3627)
- Pytorch Latent Space: [https://discuss.pytorch.org/t/plotting-the-latent-space/88431](https://discuss.pytorch.org/t/plotting-the-latent-space/88431)

## Transformers
- Implementation of paper "Attention is All You Need: [http://nlp.seas.harvard.edu/2018/04/03/attention.html](http://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding)
## Datasets
- Lionbridge: [https://lionbridge.ai/datasets/](https://lionbridge.ai/datasets/)

## Other Blog posts
- Autoencoder: [https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798#28b1](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798#28b1)
- Cosine Similarity vs Euclidean Distance: [https://cmry.github.io/notes/euclidean-v-cosine](https://cmry.github.io/notes/euclidean-v-cosine)
- Naive Bayes: [https://towardsdatascience.com/all-about-naive-bayes-8e13cef044cf](https://towardsdatascience.com/all-about-naive-bayes-8e13cef044cf)
